{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9694f7-53da-49c4-8f0b-368ad5891bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "using CategoricalArrays\n",
    "using MAT\n",
    "using DataFrames\n",
    "using MLJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869362ac-7a9e-41a0-a4b1-eac57a97d290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth targets as categories:CategoricalValue{String, UInt32}[\"Response\", \"Response\", \"Response\", \"Stable\", \"Response\", \"Stable\", \"Response\", \"Stable\", \"Remission\", \"Remission\", \"Stable\", \"Stable\", \"Response\", \"Remission\", \"Stable\", \"Stable\", \"Stable\", \"Stable\", \"Response\", \"Response\", \"Stable\", \"Stable\", \"Stable\", \"Stable\", \"Response\", \"Stable\"]\n"
     ]
    }
   ],
   "source": [
    "# sub-MOA101, sub-MOA102, sub-MOA104, sub-MOA105, sub-MOA107, sub-MOA108, sub-MOA109, sub-MOA110, sub-MOA111, sub-MOA112, sub-MOA114,\n",
    "# sub-MOA115, sub-MOA116, sub-MOA118, sub-MOA121, sub-MOA122, sub-MOA123, sub-MOA124, sub-MOA126, sub-MOA127, sub-MOA128, sub-MOA130,\n",
    "# sub-MOA131, sub-MOA133, sub-MOA134, sub-MOA135\n",
    "\n",
    "# Treatment response categories\n",
    "y = (\"Response\", \"Response\", \"Response\", \"Stable\", \"Response\", \"Stable\", \"Response\", \"Stable\", \"Remission\", \"Remission\", \"Stable\", \n",
    "    \"Stable\", \"Response\", \"Remission\", \"Stable\", \"Stable\", \"Stable\", \"Stable\", \"Response\", \"Response\", \"Stable\", \"Stable\", \"Stable\", \n",
    "    \"Stable\", \"Response\", \"Stable\")\n",
    "\n",
    "# Convert to CategoricalArray\n",
    "y_cat = categorical(collect(y))\n",
    "\n",
    "println(\"Ground truth targets as categories:\", y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1863b582-72b3-4cc1-9335-75cfc9b3f72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found Spectral_DCM.mat for 26 out of 26 subjects.\n"
     ]
    }
   ],
   "source": [
    "# List of subjects that have some degree of depression\n",
    "target_subjects = [\n",
    "    \"sub-MOA101\", \"sub-MOA102\", \"sub-MOA104\", \"sub-MOA105\", \"sub-MOA107\", \"sub-MOA108\", \"sub-MOA109\", \"sub-MOA110\", \"sub-MOA111\",\n",
    "    \"sub-MOA112\", \"sub-MOA114\", \"sub-MOA115\", \"sub-MOA116\", \"sub-MOA118\", \"sub-MOA121\", \"sub-MOA122\", \"sub-MOA123\",\"sub-MOA124\", \n",
    "    \"sub-MOA126\", \"sub-MOA127\", \"sub-MOA128\", \"sub-MOA130\", \"sub-MOA131\", \"sub-MOA133\", \"sub-MOA134\", \"sub-MOA135\"]\n",
    "\n",
    "# Base path to your subject folders\n",
    "base_path = \"Spectral_DCM_Collection_DMN\"\n",
    "\n",
    "# Collect valid file paths\n",
    "valid_files = String[]\n",
    "\n",
    "for subj in target_subjects\n",
    "    subj_path = joinpath(base_path, subj)\n",
    "    ses_path = joinpath(subj_path, \"ses-b0\")\n",
    "    glm_path = joinpath(ses_path, \"glm\")\n",
    "    dcm_file = joinpath(glm_path, \"spDCM_DMN.mat\")\n",
    "\n",
    "    if !isdir(ses_path)\n",
    "        @warn \"Missing session folder: $ses_path\"\n",
    "    elseif !isfile(dcm_file)\n",
    "        @warn \"Missing spDCM_DMN.mat for $subj\"\n",
    "    else\n",
    "        push!(valid_files, dcm_file)\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"✅ Found Spectral_DCM.mat for $(length(valid_files)) out of $(length(target_subjects)) subjects.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45eaa8ce-65ec-41b3-ae87-c89b4a34f9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extract_features (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract A matrix features as a flat 16-element vector\n",
    "function extract_features(file)\n",
    "    mat = matread(file)\n",
    "    A = mat[\"params\"]  # 4×4 matrix\n",
    "    return vec(Matrix(A))  # Flatten to 16-element vector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ac567d-e9ef-47c6-bb49-1c8c8c5566c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(X_df) = (26, 16)\n",
      "length(y_cat) = 26\n"
     ]
    }
   ],
   "source": [
    "# Create feature dataset\n",
    "X = hcat([extract_features(file) for file in valid_files]...)'\n",
    "\n",
    "X_df = DataFrame(X, :auto)  # convert to MLJ-compatible table\n",
    "\n",
    "@show size(X_df)\n",
    "@show length(y_cat)\n",
    "\n",
    "@assert size(X_df, 1) == length(y_cat) \"Mismatch between number of samples in X and y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e099112-74d5-4a2d-90a5-8c15ff4b9c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJLinearModels ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mf_tol is deprecated. Use f_abstol or f_reltol instead. The provided value (0.0001) will be used as f_reltol.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Optim ~/.julia/packages/Optim/8dE7C/src/types.jl:120\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mf_tol is deprecated. Use f_abstol or f_reltol instead. The provided value (0.0001) will be used as f_reltol.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Optim ~/.julia/packages/Optim/8dE7C/src/types.jl:120\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mf_tol is deprecated. Use f_abstol or f_reltol instead. The provided value (0.0001) will be used as f_reltol.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Optim ~/.julia/packages/Optim/8dE7C/src/types.jl:120\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PerformanceEvaluation object with these fields:\n",
       "  model, measure, operation,\n",
       "  measurement, per_fold, per_observation,\n",
       "  fitted_params_per_fold, report_per_fold,\n",
       "  train_test_rows, resampling, repeats\n",
       "Extract:\n",
       "┌───┬──────────────────────────────┬──────────────┬─────────────────────────────\n",
       "│\u001b[22m   \u001b[0m│\u001b[22m measure                      \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m measurement               \u001b[0m ⋯\n",
       "├───┼──────────────────────────────┼──────────────┼─────────────────────────────\n",
       "│ A │ Accuracy()                   │ predict_mode │ 0.538                      ⋯\n",
       "│ B │ MulticlassFScore(            │ predict_mode │ 0.519                      ⋯\n",
       "│   │   beta = 1.0,                │              │                            ⋯\n",
       "│   │   average = MacroAvg(),      │              │                            ⋯\n",
       "│   │   return_type = LittleDict,  │              │                            ⋯\n",
       "│   │   levels = nothing,          │              │                            ⋯\n",
       "│   │   perm = nothing,            │              │                            ⋯\n",
       "│   │   rev = nothing,             │              │                            ⋯\n",
       "│   │   checks = true)             │              │                            ⋯\n",
       "│ C │ ConfusionMatrix(             │ predict_mode │ ConfusionMatrix{3}([17 0 1 ⋯\n",
       "│   │   levels = nothing,          │              │                            ⋯\n",
       "│   │   perm = nothing,            │              │                            ⋯\n",
       "│   │   rev = nothing,             │              │                            ⋯\n",
       "│   │   checks = true)             │              │                            ⋯\n",
       "└───┴──────────────────────────────┴──────────────┴─────────────────────────────\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n",
       "┌───┬───────────────────────────────────────────────────────────────────────────\n",
       "│\u001b[22m   \u001b[0m│\u001b[22m per_fold                                                                \u001b[0m ⋯\n",
       "├───┼───────────────────────────────────────────────────────────────────────────\n",
       "│ A │ [0.556, 0.333, 0.75]                                                     ⋯\n",
       "│ B │ [0.413, 0.37, 0.806]                                                     ⋯\n",
       "│ C │ ConfusionMatrix{3, false, CategoricalValue{String, UInt32}}[ConfusionMat ⋯\n",
       "└───┴───────────────────────────────────────────────────────────────────────────\n",
       "\u001b[36m                                                               2 columns omitted\u001b[0m\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declare logistic regression model\n",
    "LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels\n",
    "# Build pipeline\n",
    "pipe = LogisticClassifier()\n",
    "\n",
    "# Machine\n",
    "mach = machine(pipe, X_df, y_cat)\n",
    "\n",
    "# Compatible measures\n",
    "measures = [accuracy, MulticlassFScore(), ConfusionMatrix()]\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedCV(nfolds=3, shuffle=true, rng=42)\n",
    "\n",
    "# Evaluate model\n",
    "eval_result = evaluate!(\n",
    "    mach,\n",
    "    resampling=cv,\n",
    "    measures=measures,\n",
    "    operation=predict_mode,\n",
    "    verbosity=1,\n",
    "    check_measure=false  # Force bypassing check for unsupported measures\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "914945de-0158-42ec-ad33-9df077cb07b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: \n",
      "[0, 18, 27]\n",
      "False Positives: \n",
      "[9; 9; 18;;]\n",
      "False Negatives: \n",
      "[9; 18; 9;;]\n",
      "True Positives: \n",
      "[9, 18, 0]\n",
      "False Positives: \n",
      "[0; 9; 45;;]\n",
      "False Negatives: \n",
      "[9; 36; 9;;]\n",
      "True Positives: \n",
      "[8, 16, 24]\n",
      "False Positives: \n",
      "[0; 8; 8;;]\n",
      "False Negatives: \n",
      "[0; 8; 8;;]\n",
      "Accuracies:[0.5555555555555556, 0.3333333333333333, 0.75]\n",
      "Macro Precisions:[0.4222222222222222, 0.5555555555555555, 0.8055555555555555]\n",
      "Macro Recalls:[0.4166666666666667, 0.27777777777777773, 0.8055555555555555]\n",
      "F1 Scores:[0.4126984126984127, 0.37037037037037035, 0.8055555555555555]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/Users/keyshavmor/ETH/TNM_Final_Project/Project_8/fold_grouped-metrics_logistic.png\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using Statistics\n",
    "using Plots\n",
    "using StatsPlots\n",
    "\n",
    "# Extract per-fold metrics\n",
    "accs = eval_result.per_fold[1]  # accuracy (macro)\n",
    "f1s  = eval_result.per_fold[2]  # F1 score (macro)\n",
    "cmats = eval_result.per_fold[3] # confusion matrices\n",
    "\n",
    "nfolds = length(cmats)\n",
    "\n",
    "# Initialize metric storage\n",
    "macro_precisions = Float64[]\n",
    "macro_recalls = Float64[]\n",
    "weighted_precisions = Float64[]\n",
    "weighted_recalls = Float64[]\n",
    "\n",
    "\n",
    "\n",
    "for cm in cmats\n",
    "    cmatrix = cm.mat\n",
    "    \n",
    "    TP = diag(cmatrix)\n",
    "    FP = sum(cmatrix, dims=1)' .- TP\n",
    "    FN = sum(cmatrix, dims=2) .- TP\n",
    "\n",
    "    println(\"True Positives: \\n\",TP)\n",
    "    println(\"False Positives: \\n\",FP)\n",
    "    println(\"False Negatives: \\n\",FN)\n",
    "    \n",
    "    support = sum(cmatrix, dims=2)[:]\n",
    "    total = sum(support)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    class_precisions = map((tp, fp) -> (tp + fp == 0 ? NaN : tp / (tp + fp)), TP, FP)\n",
    "    class_recalls    = map((tp, fn) -> (tp + fn == 0 ? NaN : tp / (tp + fn)), TP, FN)\n",
    "\n",
    "    # Macro average (ignores class imbalance)\n",
    "    macro_precision = mean(skipmissing(class_precisions))\n",
    "    macro_recall    = mean(skipmissing(class_recalls))\n",
    "\n",
    "    push!(macro_precisions, macro_precision)\n",
    "    push!(macro_recalls, macro_recall)\n",
    "end\n",
    "\n",
    "# Print for verification\n",
    "println(\"Accuracies:\", accs)\n",
    "println(\"Macro Precisions:\", macro_precisions)\n",
    "println(\"Macro Recalls:\", macro_recalls)\n",
    "println(\"F1 Scores:\", f1s)\n",
    "\n",
    "# Assuming these have been computed earlier:\n",
    "# accs, f1s, macro_precisions, macro_recalls\n",
    "nfolds = 3\n",
    "\n",
    "# Define metrics\n",
    "metrics = [\"Accuracy\", \"F1 Score\", \"Macro Precision\", \"Macro Recall\"]\n",
    "metric_values = [accs, f1s, macro_precisions, macro_recalls]\n",
    "\n",
    "# Prepare DataFrame\n",
    "plot_df = DataFrame(\n",
    "    Fold = repeat(1:nfolds, outer=length(metrics)),\n",
    "    Metric = repeat(metrics, inner=nfolds),\n",
    "    Value = vcat(metric_values...)\n",
    ")\n",
    "\n",
    "# Grouped bar plot with folds labeled as 1, 2, 3\n",
    "@df plot_df groupedbar(\n",
    "    string.(:Fold), :Value, group=:Metric,\n",
    "    bar_position=:dodge,\n",
    "    bar_width=0.2,\n",
    "    xlabel=\"Fold\", ylabel=\"Metric Value\",\n",
    "    title=\"Fold-wise Accuracy, F1, Precision, Recall\",\n",
    "    legend=:topright,\n",
    "    size=(1000, 600), dpi=300\n",
    ")\n",
    "\n",
    "savefig(\"fold_grouped-metrics_logistic.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5cb614-2277-4c71-b6bf-228d87073ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
