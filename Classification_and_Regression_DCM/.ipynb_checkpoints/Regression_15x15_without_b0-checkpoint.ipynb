{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9694f7-53da-49c4-8f0b-368ad5891bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/ETH/TNM_Final_Project/TNM-Safe/Project_8/Classification_and_Regression_DCM`\n"
     ]
    }
   ],
   "source": [
    "# Define the packages\n",
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()\n",
    "using CategoricalArrays\n",
    "using MAT\n",
    "using DataFrames\n",
    "using MLJ\n",
    "using LinearAlgebra\n",
    "using Statistics\n",
    "using Plots\n",
    "using StatsPlots\n",
    "using CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869362ac-7a9e-41a0-a4b1-eac57a97d290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 9, 24, 2, 17, -8, 7, 2, 30, 30, 6, 4, 12, 28, -1, -7, 3, -1, 15, 12, 8, 9, -1, 2, 18, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sub-MOA101, sub-MOA102, sub-MOA104, sub-MOA105, sub-MOA107, sub-MOA108, sub-MOA109, sub-MOA110, sub-MOA111, sub-MOA112, sub-MOA114,\n",
    "# sub-MOA115, sub-MOA116, sub-MOA118, sub-MOA121, sub-MOA122, sub-MOA123, sub-MOA124, sub-MOA126, sub-MOA127, sub-MOA128, sub-MOA130,\n",
    "# sub-MOA131, sub-MOA133, sub-MOA134, sub-MOA135\n",
    "\n",
    "# Absolute MADRS scores at session d2\n",
    "y_absolute = (24,22,17,34,21,41,18,29,0,5,31,22,22,5,26,37,27,36,9,20,25,29,29,32,17,37)\n",
    "\n",
    "# Delta change in MADRS from session b0 to session d2\n",
    "y_delta = (11,9,24,2,17,-8,7,2,30,30,6,4,12,28,-1,-7,3,-1,15,12,8,9,-1,2,18,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1863b582-72b3-4cc1-9335-75cfc9b3f72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found spDCM_rsTozzi.mat for 26 out of 26 subjects.\n"
     ]
    }
   ],
   "source": [
    "# List of subjects that have some degree of depression\n",
    "target_subjects = [\n",
    "    \"sub-MOA101\", \"sub-MOA102\", \"sub-MOA104\", \"sub-MOA105\", \"sub-MOA107\", \"sub-MOA108\", \"sub-MOA109\", \"sub-MOA110\", \"sub-MOA111\",\n",
    "    \"sub-MOA112\", \"sub-MOA114\", \"sub-MOA115\", \"sub-MOA116\", \"sub-MOA118\", \"sub-MOA121\", \"sub-MOA122\", \"sub-MOA123\",\"sub-MOA124\", \n",
    "    \"sub-MOA126\", \"sub-MOA127\", \"sub-MOA128\", \"sub-MOA130\", \"sub-MOA131\", \"sub-MOA133\", \"sub-MOA134\", \"sub-MOA135\"]\n",
    "\n",
    "# Base path to your subject folders\n",
    "base_path = \"Spectral_DCM_Collection_15x15\"\n",
    "\n",
    "# Collect valid file paths\n",
    "valid_files = String[]\n",
    "\n",
    "for subj in target_subjects\n",
    "    subj_path = joinpath(base_path, subj)\n",
    "    ses_path = joinpath(subj_path, \"ses-b0\")\n",
    "    glm_path = joinpath(ses_path, \"glm\")\n",
    "    dcm_file = joinpath(glm_path, \"spDCM_rsTozzi.mat\")\n",
    "\n",
    "    if !isdir(ses_path)\n",
    "        @warn \"Missing session folder: $ses_path\"\n",
    "    elseif !isfile(dcm_file)\n",
    "        @warn \"Missing spDCM_rsTozzi.mat for $subj\"\n",
    "    else\n",
    "        push!(valid_files, dcm_file)\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"✅ Found spDCM_rsTozzi.mat for $(length(valid_files)) out of $(length(target_subjects)) subjects.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45eaa8ce-65ec-41b3-ae87-c89b4a34f9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extract_features (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract A matrix features as a flat 16-element vector\n",
    "function extract_features(file)\n",
    "    mat = matread(file)\n",
    "    A = mat[\"params\"]  # 4×4 matrix\n",
    "    return vec(Matrix(A))  # Flatten to 16-element vector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ac567d-e9ef-47c6-bb49-1c8c8c5566c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature dataset\n",
    "X = hcat([extract_features(file) for file in valid_files]...)'\n",
    "\n",
    "X_df = DataFrame(X, :auto)  # convert to MLJ-compatible table\n",
    "\n",
    "# Ensure that the number of subjects match in X_df and Y labels of different modalities\n",
    "@assert size(X_df, 1) == length(y_absolute) \"Mismatch between number of samples in X and y_absolute\"\n",
    "@assert size(X_df, 1) == length(y_delta) \"Mismatch between number of samples in X and y_delta\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7758a5f1-0f36-43fb-98cb-57477ae49873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_regression_model (generic function with 2 methods)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLJModels, MLJScikitLearnInterface, MLJBase\n",
    "\n",
    "function evaluate_regression_model(X_df::DataFrame, y, model_label::String, nfolds::Int=5)\n",
    "    # Load and chain standardizer with model\n",
    "    Standardizer = @load Standardizer pkg=MLJModels verbosity=0\n",
    "    ElasticNetCVRegressor = @load ElasticNetCVRegressor pkg=MLJScikitLearnInterface verbosity=0\n",
    "\n",
    "    model = Standardizer() |> ElasticNetCVRegressor()\n",
    "    mach = machine(model, X_df, y)\n",
    "\n",
    "    # Metrics\n",
    "    metrics = [rms, mae]\n",
    "    metric_labels = [\"RMSE\", \"MAE\"]\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = CV(nfolds=nfolds, shuffle=true, rng=42)\n",
    "    results = evaluate!(mach,\n",
    "        resampling=cv,\n",
    "        measures=metrics,\n",
    "        operation=predict,\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "    # Extract per-fold metrics\n",
    "    all_scores = results.per_fold\n",
    "    flat_scores = vcat(all_scores...)\n",
    "\n",
    "    # Create dataframe\n",
    "    metrics_df = DataFrame(\n",
    "        Fold = 1:nfolds,\n",
    "        RMSE = all_scores[1],\n",
    "        MAE = all_scores[2]\n",
    "    )\n",
    "    avg_row = DataFrame(Fold = [\"Mean\"], RMSE = [mean(all_scores[1])],\n",
    "                        MAE = [mean(all_scores[2])])\n",
    "    metrics_table = vcat(metrics_df, avg_row)\n",
    "\n",
    "    # Save metrics table as csv\n",
    "    CSV.write(\"regression_metrics_15x15_$(nfolds)_fold_$(model_label).csv\", metrics_table)\n",
    "\n",
    "    # Prepare plot data\n",
    "    plot_df = DataFrame(\n",
    "        Fold = repeat(1:nfolds, outer=length(metrics)),\n",
    "        Metric = repeat(metric_labels, inner=nfolds),\n",
    "        Value = flat_scores\n",
    "    )\n",
    "\n",
    "    # Plot \n",
    "    @df plot_df groupedbar(\n",
    "        string.(:Fold), :Value, group=:Metric,\n",
    "        bar_position=:dodge,\n",
    "        bar_width=0.2,\n",
    "        xlabel=\"Fold\", ylabel=\"Metric Value\",\n",
    "        title=\"Regression Metrics per Fold\",\n",
    "        legend=:outertop,\n",
    "        guidefontsize=10,\n",
    "        tickfontsize=10,\n",
    "        size=(750, 500),\n",
    "        dpi=300\n",
    "    )\n",
    "    savefig(\"regression_metrics_15x15_$(nfolds)_fold_$(model_label).png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c610f2-1b59-4741-95c8-321b7918bde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/keyshavmor/ETH/TNM_Final_Project/Project_8/regression_metrics_15x15_5_fold_elasticnet_cv_absolute.png\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_regression_model(X_df, collect(y_absolute), \"elasticnet_cv_absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c0311fa-679b-46ca-a5c0-d867ec96e56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/keyshavmor/ETH/TNM_Final_Project/Project_8/regression_metrics_15x15_5_fold_elasticnet_cv_delta.png\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_regression_model(X_df, collect(y_delta), \"elasticnet_cv_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d90e6db-fc81-4092-9693-e975dddc5450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJLinearModels ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc MLJScikitLearnInterface.ElasticNetRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{Table{AbstractVector{Continuous}}, AbstractVector{Count}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/7nGJF/src/machines.jl:237\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ElasticNetRegressor(alpha = 1.0, …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc MLJScikitLearnInterface.ElasticNetRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{Table{AbstractVector{Continuous}}, AbstractVector{Count}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/7nGJF/src/machines.jl:237\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ElasticNetRegressor(alpha = 1.0, …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc MLJScikitLearnInterface.ElasticNetRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{Table{AbstractVector{Continuous}}, AbstractVector{Count}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/7nGJF/src/machines.jl:237\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ElasticNetRegressor(alpha = 1.0, …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc MLJScikitLearnInterface.ElasticNetRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{Table{AbstractVector{Continuous}}, AbstractVector{Count}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/7nGJF/src/machines.jl:237\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ElasticNetRegressor(alpha = 1.0, …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc MLJScikitLearnInterface.ElasticNetRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{Table{AbstractVector{Continuous}}, AbstractVector{Count}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/7nGJF/src/machines.jl:237\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ElasticNetRegressor(alpha = 1.0, …), …).\n"
     ]
    }
   ],
   "source": [
    "using Random\n",
    "using MLUtils\n",
    "\n",
    "@load ElasticNetRegressor pkg=MLJLinearModels\n",
    "model = ElasticNetRegressor()\n",
    "\n",
    "# Prepare 5-fold CV\n",
    "nfolds = 5\n",
    "folds = kfolds(eachindex(y_absolute), k=nfolds)\n",
    "\n",
    "y_absolute = collect(y_absolute)\n",
    "\n",
    "# Loop over folds\n",
    "all_preds = DataFrame()\n",
    "for (i, (train_indices, test_indices)) in enumerate(folds)\n",
    "    # Select training data\n",
    "    X_train = X_df[train_indices, :]\n",
    "    y_train = y_absolute[train_indices]\n",
    "\n",
    "    # Select testing data\n",
    "    X_test = X_df[test_indices, :]\n",
    "    y_test = y_absolute[test_indices]\n",
    "\n",
    "    # Train model\n",
    "    mach = machine(model, X_train, collect(y_train))\n",
    "    fit!(mach)\n",
    "    \n",
    "    # Ensure predictions are 64-bit floats\n",
    "    y_pred = predict(mach, X_test)\n",
    "    y_pred = [pred[1] for pred in y_pred]\n",
    "\n",
    "    # Sort by test sample index\n",
    "    sorted_indices = sortperm(test_indices)\n",
    "    y_test_sorted = y_test[sorted_indices]\n",
    "    y_pred_sorted = y_pred[sorted_indices]\n",
    "\n",
    "    # Plot true vs predicted\n",
    "    p = plot(\n",
    "        y_test_sorted,\n",
    "        label = \"True\",\n",
    "        lw = 2,\n",
    "        xlabel = \"Sample Index\",\n",
    "        ylabel = \"Value\",\n",
    "        title = \"ElasticNet Regression on Absolute Values_15x15: Fold $i\",\n",
    "        size=(750, 500),\n",
    "        dpi=300\n",
    "    )\n",
    "    plot!(p, y_pred_sorted, label = \"Predicted\", lw = 2, color = :orange)\n",
    "\n",
    "    # Scatter dots on top of curves\n",
    "    scatter!(p, y_test_sorted, label = \"\", marker = (:circle, 4), color = :green)\n",
    "    scatter!(p, y_pred_sorted, label = \"\", marker = (:diamond, 4), color = :red)\n",
    "\n",
    "    # Save plot\n",
    "    savefig(p, \"elasticnet_fold_$(i)_pred_vs_true_absolute_15x15.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2331d846-73cf-4f26-9eb0-084f692caeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJLinearModels ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc MLJScikitLearnInterface.ElasticNetRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{Table{AbstractVector{Continuous}}, AbstractVector{Count}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/7nGJF/src/machines.jl:237\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ElasticNetRegressor(alpha = 1.0, …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc MLJScikitLearnInterface.ElasticNetRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{Table{AbstractVector{Continuous}}, AbstractVector{Count}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/7nGJF/src/machines.jl:237\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ElasticNetRegressor(alpha = 1.0, …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc MLJScikitLearnInterface.ElasticNetRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{Table{AbstractVector{Continuous}}, AbstractVector{Count}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/7nGJF/src/machines.jl:237\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ElasticNetRegressor(alpha = 1.0, …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc MLJScikitLearnInterface.ElasticNetRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{Table{AbstractVector{Continuous}}, AbstractVector{Count}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/7nGJF/src/machines.jl:237\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ElasticNetRegressor(alpha = 1.0, …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc MLJScikitLearnInterface.ElasticNetRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{Table{AbstractVector{Continuous}}, AbstractVector{Count}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Tuple{Table{<:AbstractVector{<:Continuous}}, AbstractVector{Continuous}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/7nGJF/src/machines.jl:237\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ElasticNetRegressor(alpha = 1.0, …), …).\n"
     ]
    }
   ],
   "source": [
    "@load ElasticNetRegressor pkg=MLJLinearModels\n",
    "model = ElasticNetRegressor()\n",
    "\n",
    "# Prepare 5-fold CV\n",
    "nfolds = 5\n",
    "folds = kfolds(eachindex(y_absolute), k=nfolds)\n",
    "\n",
    "y_delta = collect(y_delta)\n",
    "\n",
    "# Loop over folds\n",
    "all_preds = DataFrame()\n",
    "for (i, (train_indices, test_indices)) in enumerate(folds)\n",
    "    # Select training data\n",
    "    X_train = X_df[train_indices, :]\n",
    "    y_train = y_delta[train_indices]\n",
    "\n",
    "    # Select testing data\n",
    "    X_test = X_df[test_indices, :]\n",
    "    y_test = y_delta[test_indices]\n",
    "\n",
    "    # Train model\n",
    "    mach = machine(model, X_train, collect(y_train))\n",
    "    fit!(mach)\n",
    "    \n",
    "    # Ensure predictions are 64-bit floats\n",
    "    y_pred = predict(mach, X_test)\n",
    "    y_pred = [pred[1] for pred in y_pred]\n",
    "\n",
    "    # Sort by test sample index\n",
    "    sorted_indices = sortperm(test_indices)\n",
    "    y_test_sorted = y_test[sorted_indices]\n",
    "    y_pred_sorted = y_pred[sorted_indices]\n",
    "\n",
    "    # Plot true vs predicted\n",
    "    p = plot(\n",
    "        y_test_sorted,\n",
    "        label = \"True\",\n",
    "        lw = 2,\n",
    "        xlabel = \"Sample Index\",\n",
    "        ylabel = \"Value\",\n",
    "        title = \"ElasticNet Regression on Delta Values_15x15: Fold $i\",\n",
    "        size=(750, 500),\n",
    "        dpi=300\n",
    "    )\n",
    "    plot!(p, y_pred_sorted, label = \"Predicted\", lw = 2, color = :orange)\n",
    "\n",
    "    # Scatter dots on top of curves\n",
    "    scatter!(p, y_test_sorted, label = \"\", marker = (:circle, 4), color = :green)\n",
    "    scatter!(p, y_pred_sorted, label = \"\", marker = (:diamond, 4), color = :red)\n",
    "\n",
    "    # Save plot\n",
    "    savefig(p, \"elasticnet_fold_$(i)_pred_vs_true_delta_15x15.png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e133d3-ccec-4752-ac25-3b6bd3577388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d044e-e30e-4386-a80d-18d118d3c53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
